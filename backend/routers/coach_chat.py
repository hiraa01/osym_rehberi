from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any, Tuple
import os
import google.generativeai as genai

from database import get_db
from core.logging_config import api_logger
from models.student import Student
from services.recommendation_engine import RecommendationEngine
from services.ml_recommendation_engine import MLRecommendationEngine


class ChatRequest(BaseModel):
    student_id: int
    message: str = Field(..., min_length=1, max_length=4000)
    use_ml: bool = True
    limit: int = 20
    w_c: Optional[float] = 0.4
    w_s: Optional[float] = 0.4
    w_p: Optional[float] = 0.2
    target_department_id: Optional[int] = None


class ChatResponse(BaseModel):
    reply: str
    used_weights: Tuple[float, float, float]
    used_ml: bool


router = APIRouter()


def _normalize_weights(w_c: Optional[float], w_s: Optional[float], w_p: Optional[float]) -> Tuple[float, float, float]:
    wc = float(w_c or 0.0)
    ws = float(w_s or 0.0)
    wp = float(w_p or 0.0)
    total = wc + ws + wp
    if total <= 0:
        return (0.4, 0.4, 0.2)
    return (wc / total, ws / total, wp / total)


@router.post("/coach", response_model=ChatResponse)
async def coach_chat(payload: ChatRequest, db: Session = Depends(get_db)):
    try:
        api_logger.info("Coach chat requested", user_id=payload.student_id)

        # Ã–ÄŸrenciyi getir
        student = db.query(Student).filter(Student.id == payload.student_id).first()
        if not student:
            raise HTTPException(status_code=404, detail="Ã–ÄŸrenci bulunamadÄ±")

        weights = _normalize_weights(payload.w_c, payload.w_s, payload.w_p)

        # âœ… Ã–nce mevcut Ã¶nerileri kontrol et (cache'den)
        from models.university import Recommendation
        existing_recs = db.query(Recommendation).filter(
            Recommendation.student_id == payload.student_id
        ).order_by(Recommendation.final_score.desc()).limit(payload.limit).all()
        
        recs: List[Dict[str, Any]] = []
        
        # EÄŸer Ã¶neriler varsa, cache'den kullan; yoksa yeni oluÅŸtur
        if existing_recs and len(existing_recs) >= payload.limit:
            api_logger.info("Using cached recommendations for coach chat", user_id=payload.student_id)
            # Cache'den gelen Ã¶nerileri dict formatÄ±na Ã§evir
            for rec in existing_recs:
                rec_dict = {
                    'final_score': rec.final_score,
                    'compatibility_score': rec.compatibility_score,
                    'success_probability': rec.success_probability,
                    'preference_score': rec.preference_score,
                    'is_safe_choice': rec.is_safe_choice,
                    'is_dream_choice': rec.is_dream_choice,
                    'is_realistic_choice': rec.is_realistic_choice,
                    'department': rec.department if hasattr(rec, 'department') else None,
                }
                recs.append(rec_dict)
        else:
            # Ã–nerileri hazÄ±rla (ML tercihiyle)
            if payload.use_ml:
                ml_engine = MLRecommendationEngine(db)
                recs = ml_engine.generate_recommendations(student_id=payload.student_id, limit=payload.limit, weights=weights)
            else:
                rule_engine = RecommendationEngine(db)
                rule_recs = rule_engine.generate_recommendations(student_id=payload.student_id, limit=payload.limit, weights=weights)
                # âœ… RecommendationResponse'larÄ± Dict'e Ã§evir
                recs = []
                for rec in rule_recs:
                    rec_dict = {
                        'final_score': rec.final_score,
                        'compatibility_score': rec.compatibility_score,
                        'success_probability': rec.success_probability,
                        'preference_score': rec.preference_score,
                        'is_safe_choice': rec.is_safe_choice,
                        'is_dream_choice': rec.is_dream_choice,
                        'is_realistic_choice': rec.is_realistic_choice,
                        'department': rec.department,
                    }
                    recs.append(rec_dict)

        # Ã–zetlenmiÅŸ Ã¶neri metni hazÄ±rla ve kategorize et
        def summarize_recs(rlist: List[Any]) -> str:
            lines: List[str] = []
            for r in rlist[: payload.limit]:
                try:
                    if isinstance(r, dict):
                        d = r
                        dept_name = d['department'].name
                        uni_id = d['department'].university_id
                        lines.append(f"- {dept_name} (uni_id={uni_id}) | final={d['final_score']:.2f} comp={d['compatibility_score']:.2f} succ={d['success_probability']:.2f} pref={d['preference_score']:.2f}")
                    else:
                        dept_name = getattr(r.department, 'name', '') if hasattr(r, 'department') else ''
                        lines.append(f"- {dept_name} | final={r.final_score:.2f} comp={r.compatibility_score:.2f} succ={r.success_probability:.2f} pref={r.preference_score:.2f}")
                except Exception:
                    continue
            return "\n".join(lines)

        rec_text = summarize_recs(recs)

        # Kategorize edilmiÅŸ kÄ±sa Ã¶zet
        def to_dict(r: Any) -> Dict[str, Any]:
            if isinstance(r, dict):
                return r
            return {
                'is_safe_choice': r.is_safe_choice,
                'is_realistic_choice': r.is_realistic_choice,
                'is_dream_choice': r.is_dream_choice,
                'final_score': r.final_score,
                'success_probability': r.success_probability,
                'department': getattr(r, 'department', None),
            }

        dlist = [to_dict(r) for r in recs]
        def topk(lst: List[Dict[str, Any]], k: int = 3) -> List[str]:
            out: List[str] = []
            for d in lst[:k]:
                dept = d.get('department')
                name = getattr(dept, 'name', '') if dept is not None else ''
                out.append(f"- {name} | final={float(d['final_score']):.2f} succ={float(d['success_probability']):.2f}")
            return out

        safe_list = [x for x in dlist if x.get('is_safe_choice')]
        realistic_list = [x for x in dlist if x.get('is_realistic_choice')]
        dream_list = [x for x in dlist if x.get('is_dream_choice')]

        categorized_text = (
            f"GÃ¼venli (ilk 3):\n" + ("\n".join(topk(safe_list)) or "- yok") + "\n\n"
            f"Realistik (ilk 3):\n" + ("\n".join(topk(realistic_list)) or "- yok") + "\n\n"
            f"Hayal (ilk 3):\n" + ("\n".join(topk(dream_list)) or "- yok")
        )

        # Hedef yakÄ±nlÄ±ÄŸÄ± (opsiyonel)
        proximity_text = ""
        if payload.target_department_id:
            try:
                from services.score_calculator import ScoreCalculator
                from models.university import Department
                dept = db.query(Department).filter(Department.id == payload.target_department_id).first()
                if dept:
                    t_tyt = 0.0
                    t_ayt = float(dept.min_score or 0.0)
                    prox = ScoreCalculator.calculate_goal_proximity(
                        student_tyt_score=float(student.tyt_total_score or 0.0),
                        student_ayt_score=float(student.ayt_total_score or 0.0),
                        target_tyt_score=t_tyt,
                        target_ayt_score=t_ayt,
                    )
                    proximity_text = (
                        f"Hedef yakÄ±nlÄ±k: overall={prox['overall_proximity']}% ayt_gap={prox['ayt_gap']} hazÄ±r_mÄ±={'evet' if prox['is_ready'] else 'hayÄ±r'}\n\n"
                    )
            except Exception:
                proximity_text = ""

        # Gemini yapÄ±landÄ±rmasÄ±
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise HTTPException(status_code=500, detail="LLM API anahtarÄ± tanÄ±mlÄ± deÄŸil (GOOGLE_API_KEY)")
        genai.configure(api_key=api_key)
        
        # âœ… Ã–nce mevcut modelleri listeleyelim
        try:
            available_models = list(genai.list_models())
            generate_models = [
                m.name for m in available_models 
                if 'generateContent' in m.supported_generation_methods
            ]
            api_logger.info(f"Available Gemini models: {generate_models[:5]}", user_id=payload.student_id)
            
            # Mevcut modellerden en uygun olanlarÄ± seÃ§
            model_names = []
            for preferred in ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro", "gemini-1.0-pro"]:
                # Model ismi tam eÅŸleÅŸme veya iÃ§erme kontrolÃ¼
                matching = [m for m in generate_models if preferred in m.lower() or preferred.replace("-", "_") in m.lower()]
                if matching:
                    model_names.extend(matching[:1])  # Ä°lk eÅŸleÅŸeni al
            
            # EÄŸer hiÃ§bir model bulunamadÄ±ysa, generate_models'ten ilk 3'Ã¼nÃ¼ al
            if not model_names and generate_models:
                model_names = generate_models[:3]
            
        except Exception as list_error:
            api_logger.warning(f"Could not list models: {str(list_error)[:50]}", user_id=payload.student_id)
            # Fallback: Standart model isimlerini dene
            model_names = [
                "gemini-1.5-flash",
                "gemini-1.5-pro", 
                "gemini-pro",
                "gemini-1.0-pro",
                "models/gemini-1.5-flash",
                "models/gemini-1.5-pro",
            ]
        
        if not model_names:
            raise HTTPException(
                status_code=500,
                detail="KullanÄ±labilir Gemini modeli bulunamadÄ±. API anahtarÄ±nÄ±zÄ± kontrol edin."
            )

        # âœ… Persona ve sistem yÃ¶nlendirmesi - GÃœNCELLENMÄ°Åž: Analitik yetenekler eklendi
        system_prompt = (
            "ROL: TÃ¼rkiye'de YKS hazÄ±rlÄ±k koÃ§usun ve Ã¼niversite tercih danÄ±ÅŸmanÄ±sÄ±n. \n"
            "STIL: Empatik, net, motive edici; kÄ±sa paragraflar, gerektiÄŸinde madde iÅŸaretleri kullan. \n"
            "VERI: Ã–ÄŸrenci ve Ã¶neri baÄŸlamÄ± aÅŸaÄŸÄ±da. Gizli/Ã¶zel verileri ifÅŸa etme. \n"
            "KAPSAM: HaftalÄ±k/aylÄ±k Ã§alÄ±ÅŸma planlarÄ±, ders daÄŸÄ±lÄ±mÄ±, kaynak Ã¶nerileri, zaman yÃ¶netimi, sÄ±nav kaygÄ±sÄ± yÃ¶netimi, \n"
            "deneme analizi ve sonuÃ§lara gÃ¶re aksiyonlar. TÄ±bbi/klinik iddialardan kaÃ§Ä±n; destek telkinleri ver. \n"
            "ANALÄ°TÄ°K YETENEKLER: \n"
            "- BÃ¶lÃ¼mlerin yÄ±llara gÃ¶re puan trendlerini analiz et (2022-2025 verileri mevcut) \n"
            "- 'Bu bÃ¶lÃ¼mÃ¼n puanÄ± 2022'den 2025'e dÃ¼zenli artÄ±ÅŸ gÃ¶stermiÅŸ, kazanmasÄ± zorlaÅŸÄ±yor' gibi Ã§Ä±karÄ±mlar yap \n"
            "- SÄ±ralama deÄŸiÅŸimlerini yorumla ve Ã¶ÄŸrenciye stratejik tavsiyeler ver \n"
            "- Puan artÄ±ÅŸ/azalÄ±ÅŸ trendlerini tespit et ve bunlarÄ± Ã¶ÄŸrenciye aÃ§Ä±kla \n"
            "Ã‡IKTI: 1) KÄ±sa Ã¶zet, 2) AdÄ±m adÄ±m plan, 3) Bu hafta gÃ¶rev listesi, 4) Ä°steÄŸe baÄŸlÄ± motivasyon cÃ¼mlesi. \n"
            "DIL: TÃ¼rkÃ§e yanÄ±t ver."
        )

        student_context = (
            f"Ã–ÄŸrenci: id={student.id}, alan={student.field_type}, sÄ±nav_tÃ¼rÃ¼={student.exam_type}, "
            f"TYT={student.tyt_total_score}, AYT={student.ayt_total_score}, TOPLAM={student.total_score}, yÃ¼zdelik={student.percentile}."
        )

        weight_context = f"AÄŸÄ±rlÄ±klar: uyumluluk={weights[0]:.2f}, baÅŸarÄ±={weights[1]:.2f}, tercih={weights[2]:.2f}."

        # âœ… Tarihsel veri context injection - BÃ¶lÃ¼m isimlerini mesajdan Ã§Ä±kar ve trend analizi yap
        historical_context = ""
        try:
            from models.university import Department, DepartmentYearlyStats
            import json
            
            # KullanÄ±cÄ± mesajÄ±ndan bÃ¶lÃ¼m isimlerini Ã§Ä±karmaya Ã§alÄ±ÅŸ (basit keyword matching)
            user_message_lower = payload.message.lower()
            department_keywords = []
            
            # Ã–nerilerden bÃ¶lÃ¼m isimlerini al
            for rec in recs[:10]:  # Ä°lk 10 Ã¶neri
                try:
                    dept = rec.get('department') if isinstance(rec, dict) else getattr(rec, 'department', None)
                    if dept:
                        dept_name = getattr(dept, 'normalized_name', None) or getattr(dept, 'name', '')
                        if dept_name and dept_name.lower() not in [k.lower() for k in department_keywords]:
                            department_keywords.append(dept_name)
                except:
                    continue
            
            # Her bÃ¶lÃ¼m iÃ§in yÄ±llara gÃ¶re trend analizi yap
            if department_keywords:
                historical_data = []
                for dept_name in department_keywords[:5]:  # Ä°lk 5 bÃ¶lÃ¼m
                    # Normalize edilmiÅŸ isme gÃ¶re bÃ¶lÃ¼mleri bul
                    depts = db.query(Department).filter(
                        Department.normalized_name == dept_name
                    ).limit(1).all()
                    
                    if depts:
                        dept = depts[0]
                        # YÄ±llÄ±k istatistikleri getir
                        yearly_stats = db.query(DepartmentYearlyStats).filter(
                            DepartmentYearlyStats.department_id == dept.id
                        ).order_by(DepartmentYearlyStats.year).all()
                        
                        if yearly_stats:
                            stats_summary = []
                            for stat in yearly_stats:
                                stats_summary.append(
                                    f"{stat.year}: min_score={stat.min_score or 'N/A'}, "
                                    f"min_rank={stat.min_rank or 'N/A'}, quota={stat.quota or 'N/A'}"
                                )
                            
                            # Trend analizi
                            scores = [s.min_score for s in yearly_stats if s.min_score]
                            if len(scores) >= 2:
                                trend = "artÄ±ÅŸ" if scores[-1] > scores[0] else "azalÄ±ÅŸ" if scores[-1] < scores[0] else "stabil"
                                trend_pct = abs((scores[-1] - scores[0]) / scores[0] * 100) if scores[0] > 0 else 0
                                historical_data.append(
                                    f"BÃ¶lÃ¼m: {dept_name}\n"
                                    f"YÄ±llÄ±k Veriler: {' | '.join(stats_summary)}\n"
                                    f"Trend: {trend} (%{trend_pct:.1f} deÄŸiÅŸim)\n"
                                )
                
                if historical_data:
                    historical_context = (
                        f"\n\nðŸ“Š TARÄ°HSEL VERÄ° ANALÄ°ZÄ° (2022-2025):\n"
                        f"{''.join(historical_data)}\n"
                        f"Bu verileri kullanarak trend analizi yap ve Ã¶ÄŸrenciye stratejik tavsiyeler ver.\n"
                    )
        except Exception as e:
            api_logger.warning(f"Historical context extraction failed: {str(e)[:100]}", user_id=payload.student_id)
            historical_context = ""

        user_message = payload.message.strip()

        prompt = (
            f"{system_prompt}\n\n"
            f"{student_context}\n{weight_context}\n"
            f"Ã–neriler (ilk {payload.limit}):\n{rec_text if rec_text else '- (Ã¶neri bulunamadÄ±)'}\n\n"
            f"{categorized_text}\n\n"
            f"{proximity_text}"
            f"{historical_context}"  # âœ… Tarihsel veri context'i eklendi
            f"KullanÄ±cÄ± mesajÄ±: {user_message}\n"
            f"Ä°stenilenler: 1) KÄ±sa ama net yanÄ±t, 2) HaftalÄ±k/aylÄ±k plan, 3) Psikolojik destek Ã¶nerileri, 4) Somut aksiyonlar, 5) Trend analizi (varsa)."
        )

        # âœ… Model deneme ve timeout handling
        import asyncio
        reply = None
        last_error = None
        
        for model_name in model_names:
            try:
                api_logger.info(f"Trying Gemini model: {model_name}", user_id=payload.student_id)
                model = genai.GenerativeModel(model_name)
                
                # generate_content Ã§aÄŸrÄ±sÄ±nÄ± dene
                completion = await asyncio.wait_for(
                    asyncio.to_thread(model.generate_content, prompt),
                    timeout=120.0  # 2 dakika timeout
                )
                reply = completion.text or ""  # type: ignore
                api_logger.info(f"Successfully used model: {model_name}", user_id=payload.student_id)
                break  # BaÅŸarÄ±lÄ± oldu, dÃ¶ngÃ¼den Ã§Ä±k
                
            except asyncio.TimeoutError:
                api_logger.warning(f"Model {model_name} timeout", user_id=payload.student_id)
                last_error = "LLM yanÄ±tÄ± Ã§ok uzun sÃ¼rdÃ¼"
                continue  # Bir sonraki modeli dene
                
            except Exception as model_error:
                error_str = str(model_error)
                api_logger.warning(f"Model {model_name} failed: {error_str[:100]}", user_id=payload.student_id)
                last_error = error_str
                continue  # Bir sonraki modeli dene
        
        if reply is None:
            # HiÃ§bir model Ã§alÄ±ÅŸmadÄ±
            api_logger.error("All Gemini models failed", user_id=payload.student_id, last_error=last_error)
            raise HTTPException(
                status_code=500,
                detail=f"AI servisinde hata: TÃ¼m modeller denenmiÅŸ ama baÅŸarÄ±sÄ±z oldu. LÃ¼tfen API anahtarÄ±nÄ±zÄ± kontrol edin."
            )

        return ChatResponse(reply=reply.strip(), used_weights=weights, used_ml=payload.use_ml)

    except HTTPException:
        raise
    except Exception as e:
        api_logger.error("Coach chat failed", error=str(e), user_id=payload.student_id)
        raise HTTPException(status_code=500, detail=f"Sohbet yanÄ±tÄ± Ã¼retilemedi: {str(e)}")


