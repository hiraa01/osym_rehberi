from sqlalchemy import create_engine, MetaData, event
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
import logging

# Logger setup
api_logger = logging.getLogger("api")

# âœ… CRITICAL: TÃœM MODELLERÄ° BURADA IMPORT ET
# SQLAlchemy'nin Base.metadata.create_all() Ã§alÄ±ÅŸmasÄ± iÃ§in
# modellerin Base'e kayÄ±t olmasÄ± gerekiyor. Bu import'lar
# Base tanÄ±mlandÄ±ktan SONRA ama create_tables() Ã§aÄŸrÄ±lmadan Ã–NCE yapÄ±lmalÄ±.
# 
# NOT: Import'larÄ± try-except iÃ§ine alarak eksik modellerin
# uygulamayÄ± Ã§Ã¶kertmesini engelliyoruz.

# Database URL - PostgreSQL for production, SQLite for development
# âœ… PostgreSQL'e geÃ§iÅŸ yapÄ±ldÄ± - performans iÃ§in kritik
# Environment variable'dan al, yoksa PostgreSQL varsayÄ±lan deÄŸerlerini kullan
# âœ… CRITICAL: Host iÃ§in birden fazla env variable kontrolÃ¼ (POSTGRES_HOST, POSTGRES_SERVER, DB_HOST)
POSTGRES_USER = os.getenv("POSTGRES_USER", "osym_user")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "osym_password")
POSTGRES_DB = os.getenv("POSTGRES_DB", "osym_rehber")
# âœ… Host iÃ§in alternatif env variable'lar: POSTGRES_HOST, POSTGRES_SERVER, DB_HOST
# âœ… CRITICAL: localhost kullanÄ±lmamalÄ±, Docker servis adÄ± ('db') kullanÄ±lmalÄ±
POSTGRES_HOST = os.getenv("POSTGRES_HOST") or os.getenv("POSTGRES_SERVER") or os.getenv("DB_HOST") or "db"
POSTGRES_PORT = os.getenv("POSTGRES_PORT", "5432")

# âœ… PostgreSQL connection string - psycopg2 driver (senkron)
# NOT: asyncpg kullanmÄ±yoruz, senkron psycopg2 kullanÄ±yoruz
# EÄŸer async kullanmak istersen: postgresql+asyncpg://...
# âœ… CRITICAL: Environment variable'dan al, yoksa varsayÄ±lan deÄŸerleri kullan
DATABASE_URL = os.getenv(
    "DATABASE_URL",
    f"postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"
)

# âœ… CRITICAL: PostgreSQL URL formatÄ±nÄ± doÄŸrula ve dÃ¼zelt
# Docker Compose'dan gelen DATABASE_URL'de driver belirtilmemiÅŸ olabilir
if not DATABASE_URL.startswith(("postgresql://", "postgresql+psycopg2://", "postgresql+asyncpg://")):
    api_logger.warning(f"âš ï¸ DATABASE_URL PostgreSQL formatÄ±nda deÄŸil: {DATABASE_URL[:30]}...")
    # EÄŸer sadece postgresql:// ile baÅŸlÄ±yorsa, psycopg2 ekle
    if DATABASE_URL.startswith("postgresql://") and "+psycopg2" not in DATABASE_URL and "+asyncpg" not in DATABASE_URL:
        DATABASE_URL = DATABASE_URL.replace("postgresql://", "postgresql+psycopg2://", 1)
        api_logger.info("âœ… DATABASE_URL psycopg2 driver ile gÃ¼ncellendi")

# âœ… CRITICAL: localhost kontrolÃ¼ - Docker iÃ§inde localhost kullanÄ±lmamalÄ±
if "localhost" in DATABASE_URL or "127.0.0.1" in DATABASE_URL:
    api_logger.warning(f"âš ï¸ DATABASE_URL'de localhost kullanÄ±lÄ±yor! Docker iÃ§inde servis adÄ± kullanÄ±lmalÄ± (Ã¶rn: 'db')")
    api_logger.warning(f"âš ï¸ Mevcut DATABASE_URL: {DATABASE_URL[:50]}...")
    # Otomatik dÃ¼zeltme (sadece uyarÄ±, deÄŸiÅŸtirme)
    api_logger.info(f"ğŸ’¡ Docker Compose'da POSTGRES_HOST='db' kullanÄ±ldÄ±ÄŸÄ±ndan emin olun")

# âœ… CRITICAL: Host adÄ±nÄ± logla (debug iÃ§in)
api_logger.info(f"ğŸ“Š Database connection config: Host={POSTGRES_HOST}, DB={POSTGRES_DB}, Port={POSTGRES_PORT}")

# Create engine with connection pooling for better performance
# âœ… PostgreSQL'e geÃ§iÅŸ yapÄ±ldÄ± - SQLite artÄ±k kullanÄ±lmÄ±yor
if DATABASE_URL.startswith("sqlite"):
    # SQLite fallback (sadece development iÃ§in)
    engine = create_engine(
        DATABASE_URL,
        connect_args={
            "check_same_thread": False,
        },
        pool_pre_ping=True,
        pool_recycle=3600,
    )
    
    @event.listens_for(engine, "connect")
    def set_sqlite_pragma(dbapi_conn, connection_record):
        """SQLite performans optimizasyonlarÄ±"""
        cursor = dbapi_conn.cursor()
        cursor.execute("PRAGMA journal_mode=WAL")
        cursor.execute("PRAGMA synchronous=NORMAL")
        cursor.execute("PRAGMA cache_size=-64000")
        cursor.execute("PRAGMA temp_store=MEMORY")
        cursor.execute("PRAGMA foreign_keys=ON")
        cursor.execute("PRAGMA optimize")
        cursor.close()
else:
    # âœ… PostgreSQL iÃ§in optimize edilmiÅŸ connection pool
    # âœ… CRITICAL: psycopg2 driver kullanÄ±yoruz (senkron)
    try:
        engine = create_engine(
            DATABASE_URL,
            pool_size=10,        # âœ… Connection pool size (kullanÄ±cÄ± isteÄŸi: 10)
            max_overflow=20,      # Additional connections beyond pool_size
            pool_pre_ping=True,  # âœ… CRITICAL: Connection health check - kopmuÅŸ baÄŸlantÄ±larÄ± tespit eder
            pool_recycle=1800,   # Recycle connections after 30 minutes (PostgreSQL'in idle timeout'undan Ã¶nce)
            pool_timeout=30,     # Wait time for connection from pool (seconds)
            echo=False,          # SQL query logging (production'da kapalÄ±)
            # âœ… PostgreSQL Ã¶zel optimizasyonlar
            connect_args={
                "connect_timeout": 20,  # Connection timeout (20 seconds)
                "application_name": "osym_rehberi_api",  # Connection identifier (pg_stat_activity'de gÃ¶rÃ¼nÃ¼r)
                "options": "-c statement_timeout=300000",  # 5 minutes query timeout (300000 ms)
                # âœ… PostgreSQL encoding ayarlarÄ±
                "client_encoding": "UTF8",
            },
        )
        api_logger.info(f"âœ… PostgreSQL engine created successfully (Host: {POSTGRES_HOST}, DB: {POSTGRES_DB})")
    except Exception as e:
        api_logger.error(f"âŒ CRITICAL: PostgreSQL engine creation failed: {e}")
        api_logger.error(f"âŒ DATABASE_URL: {DATABASE_URL[:50]}...")  # Åifreyi gÃ¶sterme
        raise

# Create session
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create base class for models
Base = declarative_base()

# Metadata for table creation
metadata = MetaData()

# âœ… IMPORT ALL MODELS (After Base is created, before create_tables is called)
# âœ… CRITICAL: models/__init__.py'den relative import kullanarak circular import'u Ã¶nle
try:
    # âœ… models paketinden import et (relative import kullanÄ±yor)
    from models import (  # noqa: F401
        User, Student, ExamAttempt,
        University, Department, DepartmentYearlyStats, Recommendation,
        Preference, Swipe,
        ForumPost, ForumComment,
        YokUniversity, YokProgram, YokCity, ScoreCalculation
    )
    # âœ… AgendaItem, StudySession, ChatMessage opsiyonel (eÄŸer varsa)
    try:
        from models import AgendaItem, StudySession, ChatMessage  # noqa: F401
    except ImportError:
        api_logger.warning("âš ï¸ AgendaItem, StudySession, ChatMessage modelleri bulunamadÄ± (opsiyonel)")
    
    api_logger.info("âœ… All models imported successfully from models package")
        
except ImportError as e:
    api_logger.error(f"âŒ CRITICAL: Failed to import models: {e}")
    api_logger.error("âŒ Some models may not be registered with Base.metadata!")
    import traceback
    api_logger.error(f"âŒ Traceback: {traceback.format_exc()}")
    # UygulamayÄ± Ã§Ã¶kertme, sadece log
    pass


def get_db():
    """Dependency to get database session"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def create_tables(max_retries: int = 3, retry_delay: int = 2):
    """
    Create all tables in the database (Auto-Migration) with retry logic
    
    NOT: Modeller zaten dosyanÄ±n Ã¼stÃ¼nde import edildi (Base.metadata'ya kayÄ±t iÃ§in).
    Bu fonksiyon sadece tablolarÄ± oluÅŸturur.
    
    Args:
        max_retries: Maksimum deneme sayÄ±sÄ± (varsayÄ±lan: 3)
        retry_delay: Her deneme arasÄ± bekleme sÃ¼resi (saniye, varsayÄ±lan: 2)
    
    Returns:
        bool: Tablolar baÅŸarÄ±yla oluÅŸturuldu ise True, aksi halde False
    """
    import time
    
    for attempt in range(1, max_retries + 1):
        try:
            api_logger.info(f"ğŸ”„ Starting database table creation (Auto-Migration)... (Deneme {attempt}/{max_retries})")
            
            # âœ… Modeller zaten import edildi (dosyanÄ±n Ã¼stÃ¼nde)
            # Sadece tablolarÄ± oluÅŸtur
            api_logger.info("ğŸ”¨ Creating database tables from registered models...")
            
            # Base.metadata'da kayÄ±tlÄ± tÃ¼m modeller iÃ§in tablolarÄ± oluÅŸtur
            Base.metadata.create_all(bind=engine)
            
            # OluÅŸturulan tablolarÄ± kontrol et
            from sqlalchemy import inspect
            inspector = inspect(engine)
            created_tables = inspector.get_table_names()
            
            api_logger.info(f"âœ… Tablolar baÅŸarÄ±yla oluÅŸturuldu! ({len(created_tables)} tablo)")
            api_logger.info(f"ğŸ“Š OluÅŸturulan tablolar: {', '.join(sorted(created_tables))}")
            
            # KayÄ±tlÄ± modelleri kontrol et
            registered_tables = list(Base.metadata.tables.keys())
            api_logger.info(f"ğŸ“‹ KayÄ±tlÄ± modeller: {len(registered_tables)} tablo metadata'da")
            
            # âœ… CRITICAL: PostgreSQL sequence'leri dÃ¼zelt (SQLite'tan geÃ§iÅŸ sonrasÄ±)
            if not DATABASE_URL.startswith("sqlite"):
                try:
                    api_logger.info("ğŸ”§ PostgreSQL sequence'leri dÃ¼zeltiliyor...")
                    from sqlalchemy import text, inspect
                    inspector = inspect(engine)
                    tables = inspector.get_table_names()
                    
                    # âœ… TÃ¼m tablolar iÃ§in sequence'leri dÃ¼zelt
                    with engine.connect() as conn:
                        for table_name in tables:
                            try:
                                # ID kolonunu bul
                                columns = inspector.get_columns(table_name)
                                id_column = None
                                for col in columns:
                                    if col.get('primary_key') and 'int' in str(col.get('type')).lower():
                                        id_column = col['name']
                                        break
                                
                                if not id_column:
                                    continue
                                
                                # Maksimum ID'yi bul
                                max_id_result = conn.execute(text(f"SELECT COALESCE(MAX({id_column}), 0) FROM {table_name}"))
                                max_id = max_id_result.scalar() or 0
                                
                                # Sequence adÄ±nÄ± bul ve dÃ¼zelt
                                seq_result = conn.execute(text(f"SELECT pg_get_serial_sequence(:table, :col)"), {"table": table_name, "col": id_column})
                                sequence_name = seq_result.scalar()
                                
                                if sequence_name:
                                    conn.execute(text(f"SELECT setval(:seq, :max_id, false)"), {"seq": sequence_name, "max_id": max_id})
                                    conn.commit()
                                    api_logger.info(f"âœ… {table_name}.{id_column}: Sequence â†’ {max_id + 1}")
                            except Exception as seq_error:
                                # Sequence yoksa veya IDENTITY kullanÄ±lÄ±yorsa normal (PostgreSQL 10+)
                                if "does not exist" not in str(seq_error).lower():
                                    api_logger.warning(f"âš ï¸ {table_name} sequence dÃ¼zeltme hatasÄ±: {seq_error}")
                                continue
                    
                    api_logger.info("âœ… Sequence'ler dÃ¼zeltildi!")
                except Exception as seq_fix_error:
                    api_logger.warning(f"âš ï¸ Sequence dÃ¼zeltme sÄ±rasÄ±nda hata (non-critical): {seq_fix_error}")
            
            return True
            
        except Exception as e:
            if attempt < max_retries:
                api_logger.warning(f"âš ï¸ Tablo oluÅŸturma hatasÄ± (Deneme {attempt}/{max_retries}): {str(e)}")
                api_logger.info(f"â³ {retry_delay} saniye bekleniyor...")
                time.sleep(retry_delay)
            else:
                api_logger.error(f"âŒ TABLO OLUÅTURMA HATASI: {e}")
                import traceback
                api_logger.error(f"âŒ Traceback: {traceback.format_exc()}")
                # Hata olsa bile uygulama Ã§alÄ±ÅŸmaya devam etsin (sadece log)
                # Ã‡Ã¼nkÃ¼ tablolar zaten var olabilir
                api_logger.warning("âš ï¸ Tablo oluÅŸturma hatasÄ±na raÄŸmen devam ediliyor (tablolar zaten var olabilir)")
                return False
    
    return False
