from sqlalchemy import create_engine, MetaData, event
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
import logging

# Logger setup
api_logger = logging.getLogger("api")

# âœ… CRITICAL: TÃœM MODELLERÄ° BURADA IMPORT ET
# SQLAlchemy'nin Base.metadata.create_all() Ã§alÄ±ÅŸmasÄ± iÃ§in
# modellerin Base'e kayÄ±t olmasÄ± gerekiyor. Bu import'lar
# Base tanÄ±mlandÄ±ktan SONRA ama create_tables() Ã§aÄŸrÄ±lmadan Ã–NCE yapÄ±lmalÄ±.
# 
# NOT: Import'larÄ± try-except iÃ§ine alarak eksik modellerin
# uygulamayÄ± Ã§Ã¶kertmesini engelliyoruz.

# Database URL - PostgreSQL for production, SQLite for development
# âœ… PostgreSQL'e geÃ§iÅŸ yapÄ±ldÄ± - performans iÃ§in kritik
# Environment variable'dan al, yoksa PostgreSQL varsayÄ±lan deÄŸerlerini kullan
POSTGRES_USER = os.getenv("POSTGRES_USER", "osym_user")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "osym_password")
POSTGRES_DB = os.getenv("POSTGRES_DB", "osym_rehber")
POSTGRES_HOST = os.getenv("POSTGRES_HOST", "db")  # Docker compose'da servis adÄ±
POSTGRES_PORT = os.getenv("POSTGRES_PORT", "5432")

# PostgreSQL connection string
DATABASE_URL = os.getenv(
    "DATABASE_URL",
    f"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"
)

# Create engine with connection pooling for better performance
# âœ… PostgreSQL'e geÃ§iÅŸ yapÄ±ldÄ± - SQLite artÄ±k kullanÄ±lmÄ±yor
if DATABASE_URL.startswith("sqlite"):
    # SQLite fallback (sadece development iÃ§in)
    engine = create_engine(
        DATABASE_URL,
        connect_args={
            "check_same_thread": False,
        },
        pool_pre_ping=True,
        pool_recycle=3600,
    )
    
    @event.listens_for(engine, "connect")
    def set_sqlite_pragma(dbapi_conn, connection_record):
        """SQLite performans optimizasyonlarÄ±"""
        cursor = dbapi_conn.cursor()
        cursor.execute("PRAGMA journal_mode=WAL")
        cursor.execute("PRAGMA synchronous=NORMAL")
        cursor.execute("PRAGMA cache_size=-64000")
        cursor.execute("PRAGMA temp_store=MEMORY")
        cursor.execute("PRAGMA foreign_keys=ON")
        cursor.execute("PRAGMA optimize")
        cursor.close()
else:
    # âœ… PostgreSQL iÃ§in optimize edilmiÅŸ connection pool
    engine = create_engine(
        DATABASE_URL,
        pool_size=20,        # Connection pool size (optimal for most cases)
        max_overflow=30,     # Additional connections beyond pool_size
        pool_pre_ping=True,  # Connection health check
        pool_recycle=1800,   # Recycle connections after 30 minutes
        pool_timeout=30,     # Wait time for connection from pool (seconds)
        echo=False,          # SQL query logging (production'da kapalÄ±)
        # PostgreSQL Ã¶zel optimizasyonlar
        connect_args={
            "connect_timeout": 20,  # Connection timeout (10 -> 20 seconds)
            "application_name": "osym_rehberi_api",  # Connection identifier
            "options": "-c statement_timeout=300000",  # 5 minutes query timeout
        },
    )

# Create session
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create base class for models
Base = declarative_base()

# Metadata for table creation
metadata = MetaData()

# âœ… IMPORT ALL MODELS FROM SINGLE FILE (After Base is created, before create_tables is called)
# TÃ¼m modeller tek dosyada (models.py) - circular import sorunu kesin Ã§Ã¶zÃ¼m
try:
    # âœ… Tek dosyadan tÃ¼m modelleri import et
    from models import (  # noqa: F401
        User, Student, ExamAttempt,
        University, Department, DepartmentYearlyStats, Recommendation,
        Preference, Swipe,
        ForumPost, ForumComment,
        AgendaItem, StudySession, ChatMessage,
        YokUniversity, YokProgram, YokCity, ScoreCalculation
    )
    api_logger.info("âœ… All models imported successfully from models.py")
        
except ImportError as e:
    api_logger.error(f"âŒ CRITICAL: Failed to import models: {e}")
    api_logger.error("âŒ Some models may not be registered with Base.metadata!")
    import traceback
    api_logger.error(f"âŒ Traceback: {traceback.format_exc()}")
    # UygulamayÄ± Ã§Ã¶kertme, sadece log
    pass


def get_db():
    """Dependency to get database session"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def create_tables(max_retries: int = 3, retry_delay: int = 2):
    """
    Create all tables in the database (Auto-Migration) with retry logic
    
    NOT: Modeller zaten dosyanÄ±n Ã¼stÃ¼nde import edildi (Base.metadata'ya kayÄ±t iÃ§in).
    Bu fonksiyon sadece tablolarÄ± oluÅŸturur.
    
    Args:
        max_retries: Maksimum deneme sayÄ±sÄ± (varsayÄ±lan: 3)
        retry_delay: Her deneme arasÄ± bekleme sÃ¼resi (saniye, varsayÄ±lan: 2)
    
    Returns:
        bool: Tablolar baÅŸarÄ±yla oluÅŸturuldu ise True, aksi halde False
    """
    import time
    
    for attempt in range(1, max_retries + 1):
        try:
            api_logger.info(f"ğŸ”„ Starting database table creation (Auto-Migration)... (Deneme {attempt}/{max_retries})")
            
            # âœ… Modeller zaten import edildi (dosyanÄ±n Ã¼stÃ¼nde)
            # Sadece tablolarÄ± oluÅŸtur
            api_logger.info("ğŸ”¨ Creating database tables from registered models...")
            
            # Base.metadata'da kayÄ±tlÄ± tÃ¼m modeller iÃ§in tablolarÄ± oluÅŸtur
            Base.metadata.create_all(bind=engine)
            
            # OluÅŸturulan tablolarÄ± kontrol et
            from sqlalchemy import inspect
            inspector = inspect(engine)
            created_tables = inspector.get_table_names()
            
            api_logger.info(f"âœ… Tablolar baÅŸarÄ±yla oluÅŸturuldu! ({len(created_tables)} tablo)")
            api_logger.info(f"ğŸ“Š OluÅŸturulan tablolar: {', '.join(sorted(created_tables))}")
            
            # KayÄ±tlÄ± modelleri kontrol et
            registered_tables = list(Base.metadata.tables.keys())
            api_logger.info(f"ğŸ“‹ KayÄ±tlÄ± modeller: {len(registered_tables)} tablo metadata'da")
            
            return True
            
        except Exception as e:
            if attempt < max_retries:
                api_logger.warning(f"âš ï¸ Tablo oluÅŸturma hatasÄ± (Deneme {attempt}/{max_retries}): {str(e)}")
                api_logger.info(f"â³ {retry_delay} saniye bekleniyor...")
                time.sleep(retry_delay)
            else:
                api_logger.error(f"âŒ TABLO OLUÅTURMA HATASI: {e}")
                import traceback
                api_logger.error(f"âŒ Traceback: {traceback.format_exc()}")
                # Hata olsa bile uygulama Ã§alÄ±ÅŸmaya devam etsin (sadece log)
                # Ã‡Ã¼nkÃ¼ tablolar zaten var olabilir
                api_logger.warning("âš ï¸ Tablo oluÅŸturma hatasÄ±na raÄŸmen devam ediliyor (tablolar zaten var olabilir)")
                return False
    
    return False
